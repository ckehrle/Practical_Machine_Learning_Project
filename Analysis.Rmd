---
title: "Practical Maschine Learning Project"
author: "Christian Kehrle"
date: "27. Dezember 2015"
output: html_document
---

# Backround

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

# Obejective
The objective of this analysis is to correctly predict the attribute "classe" for the entries in the test set.


# Processig and Exploratory Data Analysis

## Data Load

Both datasets are downloaded in separate files. When importing into dataframe we cleanse the sets for NULL values like empty fields,'NA' or '#DIV/0!' otherwise the import will face issues on detecting numeric attributes.

```{r, warning=FALSE}
library(caret, quietly=TRUE)
url_train <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
url_test <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
download.file(url = url_train, destfile = './train.csv',quiet=TRUE,mode='wb')
download.file(url = url_test, destfile = './test.csv',quiet=TRUE,mode='wb')
pml_train <- read.csv(file = 'train.csv',na.strings = c('','NA','#DIV/0!'))
pml_test <- read.csv(file = 'test.csv',na.strings  = c('','NA','#DIV/0!'))
```

## Exploratory Data Analysis

After some basic data analysis with R-functions "summary" and "str" ( We omit the output here since it just would disrupt the readability of the document.) we found out that the first 7 colummns are of dimensional character so, so we likely omit them later in feature engineering for model buuilding.

# Modeling and prediction

for the prediction we use a random forrest, since random forrest are very easy and very fast in produce an acceptable model for prediction.

## Feature enngineering

As mentioned in the prior chapter we omit the first seven columns for the model in feature list.

```{r}
feature_index <- colnames(pml_train)
feature_index <- colnames(pml_train[colSums(is.na(pml_train)) == 0])
feature_index <- feature_index[-c(1:7)]
```

## Cross validation split

For model validation, to measure up accuracy as well as keeping "Out of Sample Error" low, training data itself is split into a training and validation part. This separation is done with a fixed seed and 80% of the data for training and 20% for validation. The splitting is done per partition of the attribute "classe" to ensure availability of every all values in the training set.

```{r}
set.seed(666)
index_train <- createDataPartition(y=pml_train$classe, p=0.80, list=FALSE)
data_train <- pml_train[index_train,feature_index]
data_xval <- pml_train[-index_train,feature_index]
```

## Model training

Training or the rdanom forrest model.

```{r,warning=FALSE, results='hide', message=FALSE}
model<- train(classe ~ .,
                data = data_train, 
                method = 'rf', 
                trControl = trainControl(method = "cv", 
                                         number = 4, 
                                         allowParallel = TRUE, 
                                         verboseIter = TRUE))
```

## Variable Importance

A short overview over the influence of the single attributes to the model.

```{r}
print(plot(varImp(model, scale = FALSE)))
```

## Cross check of model performance

We apply the model to the separated training data to cross check the model quality.

```{r}
pred <- predict(model,data_xval)

results <- confusionMatrix(pred,data_xval$classe)

results
```
The accuracy of the model is 0.9941. The out of sample error is 0.0059. The out of sample error is calculated as 1 - accuracy for predictions made against the cross-validation set. 
Considering the sample size of the test set with 20 entries, an accuracy rate well above 99% is good enough to expect that none or at least only very few entries of the test samples will be mis-classified.

## Prediction

After successful cross checking our model we apply it to the real test data set where the attribute "classe" is not avaiable. In the test set there are 20 cases which need to be classified.

```{r}
final_col <- length(colnames(pml_test[]))
colnames(pml_test)[final_col] <- 'classe'
submission <- predict(model,pml_test[,feature_index])
submission
```


